{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import typing as t\n",
    "from collections import namedtuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    ")\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "Part 2 Data Exploration\n",
      "Group2_1 dataset:\n",
      "\n",
      "count    169.000000\n",
      "mean      72.079053\n",
      "std       62.982411\n",
      "min        3.540000\n",
      "25%        3.540000\n",
      "50%       66.140000\n",
      "75%      119.680000\n",
      "max      203.150000\n",
      "Name: Value, dtype: float64 \n",
      "\n",
      "Group2_2 dataset:\n",
      "\n",
      "count    164.000000\n",
      "mean      97.530183\n",
      "std      107.704447\n",
      "min        5.510000\n",
      "25%        9.155000\n",
      "50%       71.060000\n",
      "75%      147.832500\n",
      "max      470.470000\n",
      "Name: Value, dtype: float64 \n",
      "\n",
      "The Group2_2 dataset is more variable -> assuming it is the glass dataset.\n",
      "****************************************************************\n",
      "2 a) Create three predictors...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_385226/963353629.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Time\"] = pd.to_datetime(df[\"Time\"])\n",
      "/tmp/ipykernel_385226/963353629.py:35: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Time\"] = pd.to_datetime(df[\"Time\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Obstacle_Type</th>\n",
       "      <th>Angle_Approach</th>\n",
       "      <th>Time_Collision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-15 16:40:57</td>\n",
       "      <td>189.37</td>\n",
       "      <td>Concrete</td>\n",
       "      <td>6.567914</td>\n",
       "      <td>7.890417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-15 16:40:58</td>\n",
       "      <td>186.22</td>\n",
       "      <td>Concrete</td>\n",
       "      <td>5.185762</td>\n",
       "      <td>7.759167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-15 16:40:58</td>\n",
       "      <td>88.58</td>\n",
       "      <td>Concrete</td>\n",
       "      <td>5.700221</td>\n",
       "      <td>3.690833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-15 16:40:59</td>\n",
       "      <td>88.58</td>\n",
       "      <td>Concrete</td>\n",
       "      <td>9.863451</td>\n",
       "      <td>3.690833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-15 16:40:59</td>\n",
       "      <td>88.58</td>\n",
       "      <td>Concrete</td>\n",
       "      <td>11.063295</td>\n",
       "      <td>3.690833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2024-11-15 16:41:17</td>\n",
       "      <td>3.54</td>\n",
       "      <td>Concrete</td>\n",
       "      <td>10.440101</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2024-11-15 16:41:17</td>\n",
       "      <td>3.54</td>\n",
       "      <td>Concrete</td>\n",
       "      <td>11.541373</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2024-11-15 16:41:17</td>\n",
       "      <td>3.54</td>\n",
       "      <td>Concrete</td>\n",
       "      <td>6.445455</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2024-11-15 16:41:17</td>\n",
       "      <td>3.54</td>\n",
       "      <td>Concrete</td>\n",
       "      <td>12.515278</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2024-11-15 16:41:17</td>\n",
       "      <td>3.54</td>\n",
       "      <td>Concrete</td>\n",
       "      <td>7.220491</td>\n",
       "      <td>0.147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Time  Distance Obstacle_Type  Angle_Approach  \\\n",
       "0   2024-11-15 16:40:57    189.37      Concrete        6.567914   \n",
       "1   2024-11-15 16:40:58    186.22      Concrete        5.185762   \n",
       "2   2024-11-15 16:40:58     88.58      Concrete        5.700221   \n",
       "3   2024-11-15 16:40:59     88.58      Concrete        9.863451   \n",
       "4   2024-11-15 16:40:59     88.58      Concrete       11.063295   \n",
       "..                  ...       ...           ...             ...   \n",
       "164 2024-11-15 16:41:17      3.54      Concrete       10.440101   \n",
       "165 2024-11-15 16:41:17      3.54      Concrete       11.541373   \n",
       "166 2024-11-15 16:41:17      3.54      Concrete        6.445455   \n",
       "167 2024-11-15 16:41:17      3.54      Concrete       12.515278   \n",
       "168 2024-11-15 16:41:17      3.54      Concrete        7.220491   \n",
       "\n",
       "     Time_Collision  \n",
       "0          7.890417  \n",
       "1          7.759167  \n",
       "2          3.690833  \n",
       "3          3.690833  \n",
       "4          3.690833  \n",
       "..              ...  \n",
       "164        0.147500  \n",
       "165        0.147500  \n",
       "166        0.147500  \n",
       "167        0.147500  \n",
       "168        0.147500  \n",
       "\n",
       "[169 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Your Python code should create three predictors (Distance, Obstacle_Type, Angle_Approach) and one output variable (Time_Collision)\n",
    "\n",
    "print(\"****************************************************************\")\n",
    "print(\"Part 2 Data Exploration\")\n",
    "# Load the two datasets\n",
    "\n",
    "# Looking at the csv contents I'm guessing the Group2_2 is the glass dataset since there's more vairablity\n",
    "# in the values on first inspection (glass refracts more than concrete).\n",
    "concrete_candidate_df = pd.read_csv(os.path.join(\"data\", \"Group2_1.csv\"))\n",
    "glass_candidate_df = pd.read_csv(os.path.join(\"data\", \"Group2_2.csv\"))\n",
    "\n",
    "\n",
    "# I can confirm this by using .describe() for the distance/ \"Value\" column.=\n",
    "\n",
    "# summary_file1, summary_file2\n",
    "print(\"Group2_1 dataset:\\n\")\n",
    "print(concrete_candidate_df[\"Value\"].describe(), \"\\n\")\n",
    "print(\"Group2_2 dataset:\\n\")\n",
    "print(glass_candidate_df[\"Value\"].describe(), \"\\n\")\n",
    "print(\"The Group2_2 dataset is more variable -> assuming it is the glass dataset.\")\n",
    "\n",
    "print(\"****************************************************************\")\n",
    "print(\"2 a) Create three predictors...\")\n",
    "# Assign Obstacle_Type based on assumed identifications\n",
    "np.random.seed(1)\n",
    "for df, obs_type in zip(\n",
    "    [glass_candidate_df, concrete_candidate_df], [\"Glass\", \"Concrete\"]\n",
    "):\n",
    "    # black magic line\n",
    "    df[\"Obstacle_Type\"] = pd.Series(obs_type, np.arange(len(df))).astype(\"category\")\n",
    "    df[\"Angle_Approach\"] = (10 if obs_type == \"Concrete\" else 0) + np.random.uniform(\n",
    "        -5, 5, size=len(df)\n",
    "    )\n",
    "    df[\"Time_Collision\"] = df[\"Value\"] / 24\n",
    "    df[\"Time\"] = pd.to_datetime(df[\"Time\"])\n",
    "    df.rename(columns={\"Value\": \"Distance\"}, inplace=True)\n",
    "\n",
    "\n",
    "concrete_candidate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "2 b) Trim a few seconds of last rows of data...\n"
     ]
    }
   ],
   "source": [
    "# b) Your team can trim a few seconds of last rows of data where the same distance “Value” column in the datasets is exactly repeated.\n",
    "\n",
    "print(\"****************************************************************\")\n",
    "print(\"2 b) Trim a few seconds of last rows of data...\")\n",
    "\n",
    "\n",
    "def strip_similar_rows(\n",
    "    df: pd.DataFrame,\n",
    "    columns: str | list[str],\n",
    "    side: t.Literal[\"start\", \"end\", \"both\"] = \"end\",\n",
    "    thresh=0.1,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    THIS MUTATES THE DF\n",
    "\n",
    "    strips the rows that are similar to the last row (acc to `tresh`), but leaves the last\n",
    "    expects the dataframe to have an integer index\n",
    "\n",
    "    args:\n",
    "        - df (DataFrame): the dataframe to operate on\n",
    "        - columns (str | list[str]): column(s) of the values to compare\n",
    "        - side (\"start\", \"end\", \"both\"): where to strip rows, default \"end\"\n",
    "        - tresh (float): +/- val to consider \\n\n",
    "    returns:\n",
    "        - None\n",
    "\n",
    "    \"\"\"\n",
    "    Row = namedtuple(\"Row\", [\"index\", \"series\"])\n",
    "    last = df[columns].iloc[-1]\n",
    "    if side == \"both\":\n",
    "        side = \"end\"\n",
    "        strip_similar_rows(df, columns, \"start\", thresh)\n",
    "    # iterrows() is a bad idea but whatever\n",
    "    rows_since_dupe = 0\n",
    "    to_drop: list[Row] = []\n",
    "    for i, row in (df[::-1] if side == \"end\" else df).iterrows():\n",
    "        if rows_since_dupe > 1:\n",
    "            break\n",
    "        if not (last - thresh <= row[columns] <= last + thresh):\n",
    "            rows_since_dupe += 1\n",
    "            continue\n",
    "        to_drop.append(Row(i, row))\n",
    "    df.drop(index=[i.index for i in to_drop], inplace=True)\n",
    "    df.loc[len(df)] = to_drop[-1].series\n",
    "\n",
    "\n",
    "strip_similar_rows(glass_candidate_df, \"Distance\", \"end\", 0.2)\n",
    "strip_similar_rows(concrete_candidate_df, \"Distance\", \"end\", 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************\n",
      "2 c) Deal with seconds that do not have exactly 10 records...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'numeric_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m numeric_cols: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m (concrete_candidate_df, glass_candidate_df):\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mnumeric_cols\u001b[49m:\n\u001b[1;32m      7\u001b[0m         numeric_cols \u001b[38;5;241m=\u001b[39m [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_numeric_dtype(df[c])]\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _time, _count \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcount()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistance\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numeric_cols' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"****************************************************************\")\n",
    "print(\"2 c) Deal with seconds that do not have exactly 10 records...\")\n",
    "\n",
    "numeric_cols: list[str] | None = None\n",
    "for df in (concrete_candidate_df, glass_candidate_df):\n",
    "    if not numeric_cols:\n",
    "        numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    for _time, _count in df.groupby(\"Time\").count()[\"Distance\"].items():\n",
    "        row_to_opp = df.loc[(df[\"Time\"] == _time)]  # row to operate on\n",
    "        if row_to_opp.empty:\n",
    "            continue\n",
    "        for _ in range(_count - 10):\n",
    "            df.drop(index=row_to_opp.iloc[0].index, inplace=True)\n",
    "            _count -= 1\n",
    "        if _count == 10:\n",
    "            continue\n",
    "        new_row: pd.Series = row_to_opp[numeric_cols].mean()\n",
    "        for col in (c for c in df.columns if c not in numeric_cols):\n",
    "            new_row[col] = row_to_opp[col].iloc[0]  # fill in non-numeric-cols\n",
    "        for _ in range(10 - _count):\n",
    "            df.loc[len(df)] = new_row\n",
    "    df.sort_values([\"Time\", \"Distance\"], ascending=[True, False], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"****************************************************************\")\n",
    "print(\"2 d) Report and handle missing and outlier values\")\n",
    "# print(data_combined.isnull().sum())\n",
    "for df in (concrete_candidate_df, glass_candidate_df):\n",
    "    if any((_nulldf := df.isnull()).any().to_dict().values()):\n",
    "        print(\n",
    "            f\"null vals @ {_nulldf.loc[_nulldf[_nulldf.columns[0]]==True].index} prolly cause last oper, just gonna drop\"\n",
    "        )\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "def drop_outliers(df: pd.DataFrame, column: str, multip: float = 1.5):\n",
    "    \"\"\"use iqr to handle outliers\n",
    "\n",
    "    mutates original df and returns a shallow ref\n",
    "    \"\"\"\n",
    "    _q1 = df[column].quantile(0.25)\n",
    "    _q3 = df[column].quantile(0.75)\n",
    "    iqr = _q3 - _q1\n",
    "    lower_bound = _q1 - multip * iqr\n",
    "    upper_bound = _q3 + multip * iqr\n",
    "\n",
    "    df[column] = np.where(df[column] < lower_bound, lower_bound, df[column])\n",
    "    df[column] = np.where(df[column] > upper_bound, upper_bound, df[column])\n",
    "    return df\n",
    "\n",
    "\n",
    "for df in (concrete_candidate_df, glass_candidate_df):\n",
    "    for col in numeric_cols:\n",
    "        drop_outliers(df, col)\n",
    "\n",
    "print(\"\\nSummary Statistics After Handling Outliers:\")\n",
    "\n",
    "data_combined = pd.concat([concrete_candidate_df, glass_candidate_df])\n",
    "data_combined.to_csv(os.path.join(\"data\", \"out.csv\"), index=False)\n",
    "data_combined[numeric_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"****************************************************************\")\n",
    "print(\"2 e) Make Two Plots [Box Plot and Line Plot]\")\n",
    "\n",
    "# Box Plot: Distance by Obstacle Type\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=\"Obstacle_Type\", y=\"Distance\", data=data_combined)\n",
    "plt.title(\"Box Plot of Distance by Obstacle Type\")\n",
    "plt.xlabel(\"Obstacle Type\")\n",
    "plt.ylabel(\"Distance (inches)\")\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plot: Average Distance over Time with Separate Axes for Each Obstacle Type\n",
    "# Aggregate data to calculate average distance per second for each obstacle type\n",
    "data_combined[\"Second\"] = data_combined[\"Time\"].dt.floor(\"S\")\n",
    "avg_distance_per_second = (\n",
    "    data_combined.groupby([\"Second\", \"Obstacle_Type\"])[\"Distance\"].mean().reset_index()\n",
    ")\n",
    "\n",
    "# Create separate scatter plots for glass and concrete\n",
    "axes: list[plt.Axes]\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharey=True)\n",
    "\n",
    "# Scatter plot for Glass\n",
    "sns.scatterplot(\n",
    "    ax=axes[0],\n",
    "    x=\"Second\",\n",
    "    y=\"Distance\",\n",
    "    data=avg_distance_per_second[avg_distance_per_second[\"Obstacle_Type\"] == \"Glass\"],\n",
    "    color=\"blue\",\n",
    ")\n",
    "axes[0].set_title(\"Average Distance over Time (Glass)\")\n",
    "axes[0].set_xlabel(\"Time (per second)\")\n",
    "axes[0].set_ylabel(\"Average Distance (inches)\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# Scatter plot for Concrete\n",
    "sns.scatterplot(\n",
    "    ax=axes[1],\n",
    "    x=\"Second\",\n",
    "    y=\"Distance\",\n",
    "    data=avg_distance_per_second[\n",
    "        avg_distance_per_second[\"Obstacle_Type\"] == \"Concrete\"\n",
    "    ],\n",
    "    color=\"green\",\n",
    ")\n",
    "axes[1].set_title(\"Average Distance over Time (Concrete)\")\n",
    "axes[1].set_xlabel(\"Time (per second)\")\n",
    "axes[1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Heat Map\n",
    "# Select only numeric columns for the heatmap\n",
    "numeric_data = data_combined[[\"Distance\", \"Angle_Approach\", \"Time_Collision\"]]\n",
    "ax_heatmap = sns.heatmap(\n",
    "    numeric_data.corr(),  # Use correlation matrix for better visualization\n",
    "    xticklabels=numeric_data.columns.to_list(),\n",
    "    yticklabels=numeric_data.columns.to_list(),\n",
    "    cmap=\"RdBu\",\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    center=0,\n",
    ")\n",
    "ax_heatmap.set_title(\n",
    "    \"Correlation and effect of Distance, Angle_Approach, and Time_Collisoin upon each other\"\n",
    ")\n",
    "ax_heatmap.set_xlabel(\"Features\")\n",
    "ax_heatmap.set_ylabel(\"Features\")\n",
    "plt.show()\n",
    "\n",
    "# Adding a Histogram of Time_Collision\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(\n",
    "    data_combined[\"Time_Collision\"],\n",
    "    bins=20,\n",
    "    alpha=0.7,\n",
    "    color=\"blue\",\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "plt.title(\"Histogram of Time_Collision\")\n",
    "plt.xlabel(\"Time to Collision (seconds)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"****************************************************************\")\n",
    "print(\"2 f) Combine the two datasets for both scenarios\")\n",
    "print(\n",
    "    \"The datasteps were combined in 2 d). But we can still confirm the dataframe row count using .shape():\"\n",
    ")\n",
    "print(data_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"****************************************************************\")\n",
    "print(\"2 g) Shuffle data to avoid data overfitting when using k-NN and Naive Bayes\")\n",
    "\n",
    "\n",
    "final_data_shuffled = pd.get_dummies(\n",
    "    data_combined.sample(frac=1, random_state=42).reset_index(drop=True),\n",
    "    columns=[\"Obstacle_Type\"],\n",
    "    dtype=int,\n",
    "    drop_first=True,\n",
    ")\n",
    "\n",
    "# final_data_shuffled.to_csv(os.path.join(\"data\", \"out.csv\"), index=False)\n",
    "final_data_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"****************************************************************\")\n",
    "print(\"Part 3 Model Training\")\n",
    "\n",
    "# Define features and target variable\n",
    "\n",
    "\n",
    "features = final_data_shuffled[[\"Distance\", \"Angle_Approach\", \"Obstacle_Type_Glass\"]]\n",
    "target = final_data_shuffled[\"Time_Collision\"]\n",
    "\n",
    "# Split data into 60% training and 40% validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    features, target, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"****************************************************************\")\n",
    "print(\"3 a) k-NN model\")\n",
    "# Initialize the k-NN model (you can start with k=5 or any other reasonable choice)\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Train the k-NN model\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = knn.predict(X_val_scaled)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(\"k-NN Model Performance:\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R-squared (R2 Score): {r2}\")\n",
    "print(\n",
    "    \"Use a 5-fold cross-validation to confirm not Overfitting. If the scores vary wildly, this would indicate Overfitting.\"\n",
    ")\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(knn, features, target, cv=5, scoring=\"r2\")\n",
    "print(\"Cross-Validation R-squared Scores:\", cv_scores)\n",
    "print(\"Average Cross-Validation R-squared:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"****************************************************************\")\n",
    "print(\"3 b) Naïve Bayes model\")\n",
    "\n",
    "final_data_shuffled[\"Time_Collision_Label\"] = final_data_shuffled[\n",
    "    \"Time_Collision\"\n",
    "].apply(lambda x: \"Close\" if x < 2 else \"Mid\" if x < 6 else \"Far\")\n",
    "\n",
    "\n",
    "# Step 2: Discretize Distance and Angle_Approach\n",
    "# Using KBinsDiscretizer to create bins\n",
    "discretizer = KBinsDiscretizer(n_bins=5, encode=\"ordinal\", strategy=\"uniform\")\n",
    "discrete_features = discretizer.fit_transform(\n",
    "    final_data_shuffled[[\"Distance\", \"Angle_Approach\"]]\n",
    ")\n",
    "final_data_shuffled[[\"Distance_binned\", \"Angle_Approach_binned\"]] = discrete_features\n",
    "\n",
    "# Step 3: Define features and target variable\n",
    "features = final_data_shuffled[\n",
    "    [\"Distance_binned\", \"Angle_Approach_binned\", \"Obstacle_Type_Glass\"]\n",
    "]\n",
    "\n",
    "target = final_data_shuffled[\"Time_Collision_Label\"]\n",
    "\n",
    "# Step 4: Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    features, target, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "# Step 5: Train the Multinomial Naive Bayes model\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Validate the model\n",
    "y_pred = nb.predict(X_val)\n",
    "\n",
    "# Step 7: Report results\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "report = classification_report(y_val, y_pred)\n",
    "\n",
    "print(\"Multinomial Naive Bayes Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"****************************************************************\")\n",
    "print(\"Part 4 New Record Regression/Classification\")\n",
    "\n",
    "# Select one or a few random data points from the dataset\n",
    "# Adjust n to select more samples if needed\n",
    "random_samples = final_data_shuffled.sample(n=10, random_state=1)\n",
    "\n",
    "# Separate features and true target values for the selected samples\n",
    "knn_features = random_samples[[\"Distance\", \"Angle_Approach\", \"Obstacle_Type_Glass\"]]\n",
    "nb_features = random_samples[\n",
    "    [\"Distance_binned\", \"Angle_Approach_binned\", \"Obstacle_Type_Glass\"]\n",
    "]\n",
    "true_time_collision = random_samples[\"Time_Collision\"]\n",
    "true_time_collision_label = random_samples[\"Time_Collision_Label\"]\n",
    "\n",
    "# k-NN model prediction on continuous features\n",
    "knn_prediction = knn.predict(knn_features)\n",
    "\n",
    "# Naive Bayes model prediction on discretized features\n",
    "nb_prediction = nb.predict(nb_features)\n",
    "\n",
    "# Display the results\n",
    "for i in range(len(random_samples)):\n",
    "    print(f\"Data Point {i+1}:\")\n",
    "    print(f\"  True Time_Collision: {true_time_collision.iloc[i]}\")\n",
    "    print(f\"  True Category (NB): {true_time_collision_label.iloc[i]}\")\n",
    "    print(f\"  k-NN Predicted Time_Collision: {knn_prediction[i]}\")\n",
    "    print(f\"  Naive Bayes Predicted Category: {nb_prediction[i]}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
